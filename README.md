
# ğŸ§  AI Lawyer Chatbot â€“ RAG with LangChain + Groq + FAISS

This is an AI-powered legal assistant chatbot built using **LangChain**, **Grok (DeepSeek)** for inference, **FAISS** for vector storage, and **Sentence Transformers** for text embeddings. The chatbot uses Retrieval-Augmented Generation (RAG) to answer user queries based on uploaded legal PDFs.

---

## ğŸš€ Features

- âš–ï¸ **Legal Domain Focus** â€“ Ask legal questions based on custom PDFs
- ğŸ” **RAG Pipeline** â€“ Combines LLM reasoning with document retrieval
- ğŸ§  **Grok/DeepSeek** â€“ Fast and powerful inference using Groq API
- ğŸ§© **Sentence Transformers** â€“ Converts text chunks into vector embeddings
- ğŸ—‚ï¸ **FAISS Vector Store** â€“ Efficient storage and retrieval of document chunks
- ğŸ“„ **PDF Support** â€“ Upload and process legal documents

---

## ğŸ› ï¸ Tech Stack

| Component            | Library / Tool                          |
|---------------------|------------------------------------------|
| LLM Inference        | `groq` (DeepSeek model)                 |
| Framework            | `LangChain`                             |
| Embeddings           | `sentence-transformers` (`MiniLM`)      |
| Vector Database      | `FAISS`                                 |
| Document Loader      | `PyPDFLoader`, `DirectoryLoader`        |
| Prompt Management    | `LangChain PromptTemplate`              |
| Environment Config   | `python-dotenv`                         |
| Language             | `Python 3.10+`                          |

---

## âš™ï¸ How It Works

1. **PDF Upload** â€“ Upload your legal PDF documents.
2. **Text Chunking** â€“ The text is split into manageable chunks using recursive character splitting.
3. **Vectorization** â€“ Chunks are converted into dense vector embeddings using Sentence Transformers.
4. **Storage** â€“ Embeddings are stored in a FAISS vector database.
5. **RAG Querying** â€“ User inputs are embedded and relevant chunks are retrieved.
6. **LLM Inference** â€“ The question and retrieved context are sent to Groq (DeepSeek) for response generation.

---

## ğŸ“¦ Installation

```bash
git clone "https://github.com/Haseeb1511/AI_lawyer_chatbot.git"
python -m venv venv
source venv/bin/activate   # or venv\Scripts\activate on Windows
pip install -r requirements.txt
```

---

## ğŸ”‘ Environment Variables

Create a `.env` file with your API keys:

```env
GROQ_API_KEY=your_groq_api_key
```

---

## â–¶ï¸ Run the App

```bash
streamlit run app.py
```

---

## ğŸ§ª Example Query

> â€œCan you explain the clause related to breach of contract in this document?â€

---

## ğŸ“š TODOs

- [ ] Add support for follow-up questions (chat history)
- [ ] Integrate multiple embedding models
- [ ] Add citation references to sources
- [ ] Dockerize the project

---

## ğŸ“„ License

This project is licensed under the [MIT License](LICENSE).

---
